# - Tidyverse -----------------------------------------------------------------
# - readr, dplyr, tidyr, lubridate, stringr -----------------------------------
	
	
# readr

	# Read tabular data
	library(readr)
	teams <- read_csv("data/team_standings.csv")
	OR
	teams <- read_csv("data/team_standings.csv", col_types = "cc")
	
	logs <- read_csv("data/2016-07-20.csv.gz", col_types = "ccicccccci", n_max = 10)
	
	# Keep only one column
	logdates <- read_csv("data/2016-07-20.csv.gz", 
                     col_types = cols_only(date = col_date()),
                     n_max = 10)
					 
	read_csv	Reads comma-separated file
	read_csv2	Reads semicolon-separated file
	read_tsv	Reads tab-separated file
	read_delim	General function for reading delimited files
	read_fwf	Reads fixed width files
	read_log	Reads log files
	
	
	# Read web based data
	ext_tracks_file <- paste0("http://rammb.cira.colostate.edu/research/",
                          "tropical_cyclones/tc_extended_best_track_dataset/",
                          "data/ebtrk_atlc_1988_2015.txt")
	ext_tracks_widths <- c(7, 10, 2, 2, 3, 5, 5, 6, 4, 5, 4, 4, 5, 3, 4, 3, 3, 3,
                       4, 3, 3, 3, 4, 3, 3, 3, 2, 6, 1)
	ext_tracks_colnames <- c("storm_id", "storm_name", "month", "day",
                          "hour", "year", "latitude", "longitude",
                          "max_wind", "min_pressure", "rad_max_wind",
                          "eye_diameter", "pressure_1", "pressure_2",
                          paste("radius_34", c("ne", "se", "sw", "nw"), sep = "_"),
                          paste("radius_50", c("ne", "se", "sw", "nw"), sep = "_"),
                          paste("radius_64", c("ne", "se", "sw", "nw"), sep = "_"),
                          "storm_type", "distance_to_land", "final")

	# Read the file in from its url
	ext_tracks <- read_fwf(ext_tracks_file, 
                       fwf_widths(ext_tracks_widths, ext_tracks_colnames),
                       na = "-99")

					   
# dplyr

	library(dplyr)
	
	tbl <- tbl_df(df)
		Dataframe to dataframe tbl
	select(x, a:b)
		Keeps only the columns a to b
	select(x, -(a:b))
		Keeps everything but the columns a to b
	filter(x, a > 30)
		Keeps the values of x where a > 30 (works like subset())
	arrange(x, desc(date))
		Sort, here in descending order, x along date
	rename(x, newC = oldC, newC2 = oldC2)
		Rename columns 
	mutate(x, newC = col - mean(col))
		Add a new column newC
	summarise(x, a = mean(a), b = max(b), c = median(c))
		Summarize x along what you ask. Works better when you use group_by() before.
	mammals %>% arrange(adult_body_mass_g)
		Pipeline operator, which avoids temp variable.

	# Examples and piping
	ext_tracks %>%
	  filter(storm_name == "KATRINA") %>%
	  select(month, day, hour, max_wind, min_pressure, rad_max_wind) %>%
	  sample_n(4)	
				   
	ext_tracks %>%
	group_by(storm_name, year) %>%
	summarize(n_obs = n(),
            worst_wind = max(max_wind),
            worst_pressure = min(min_pressure))
	
	library(ggplot2)
	ext_tracks %>%
	group_by(storm_name) %>%
	summarize(worst_wind = max(max_wind)) %>%
	ggplot(aes(x = worst_wind)) + geom_histogram() 
		
	# Advanced dplyr commands
	titanic_4 <- titanic %>% 
		select(Survived, Pclass, Age, Sex) %>%
		filter(!is.na(Age)) %>%
		mutate(agecat = cut(Age, breaks = c(0, 14.99, 50, 150), 
						  include.lowest = TRUE,
						  labels = c("Under 15", "15 to 50", "Over 50"))) %>%
		group_by(Pclass, agecat, Sex) %>%
		summarize(N = n(),
				survivors = sum(Survived == 1),
				perc_survived = 100 * survivors / N)
		
	wc_4 <- worldcup %>% 
		select(Time, Passes, Tackles, Saves) %>%
		summarize(Time = mean(Time),
				Passes = mean(Passes),
				Tackles = mean(Tackles),
				Saves = mean(Saves)) %>%
		gather(var, mean) %>%
		mutate(mean = round(mean, 1))
	
	
# lubridate

	d1 = date()						# Returns character
	d2 = Sys.Date()					# Returns Date
	
	format(d2,"%a %b %d")			# Reformat Dates
	
	# You can substract Dates
	x = c("1jan1960", "2jan1960")
	z = as.Date(x, "%d%b%Y")
	as.numeric(z[1]-z[2])
	
	weekdays(d2)					# Gives the day of the week
	months(d2)						# Gives the month
	julian(d2)						# Gives the number of day since 1970-01-01
	
	
	# lubridate caste a string to Date
	library(lubridate)
	ymd("20140108")					# Year Month Day
	mdy("08/04/2013")				# Month Day Year
	dmy("03-04-2013")				# Day Month Year
	ymd_hms("2011-08-03 10:15:03",tz="Pacific/Auckland")
									# Year Month Day Hour Minute Second with timezone
	wday(x[1])						# Get weekday (integer)
	wday(x[1],label=TRUE)			# Get weekday (factor)
	
	
# stingr
	library(stringr)
	
	str_extract(s, regex)	Extract the regex from s
	str_order(s)			Returns indices so that s is in alphabetical order
	str_pad("Thai", width = 8, side = "both", pad = "-")
	[1] "--Thai--"			Pad a string left/right/both
	str_to_title()			Capitalize a string
	str_trim()				Remove whitespace from both side of a string
	str_wrap(s, width = 80)	Insert a newline as soon as the width is exceeded
	word(s, start, end)		Allows to index a sentence using start, end
	
	Human readable regex: rex
	https://github.com/kevinushey/rex
	Test regex online
	http://regexr.com/
	Tidy Text Mining with R
	http://tidytextmining.com/index.html
	
# -----------------------------------------------------------------------------	

	
# Data tables - faster and more efficient than data frames	
	
	library(data.table)
	DF = data.frame(x=x, y=y, z=z)
	DT = data.table(x=x, y=y, z=z)
	tables()		# See all tables in memory
	
	DT[2,]			# Subset a row
	DT[DT$y="a"]	# Extracts rows where only y="a"
	
	# Working with columns is different:
	# Anything after the first comma is considered by R as an expression
	DT[,list(mean(x), sum(z))]
	DT[,table(y)]
	
	# Adding columns
	DT[, newCol := z^2]
	DT[, newCol := {tmp <- x+z; log2(tmp+5)}]
	DT[, a := x > 0 ]
	DT[, b := mean(x+w), by = a] 
				# Puts mean(x+w) where a = TRUE and 
				# Puts mean(x+w) where a = FALSE			
	DT[, .N, by = x]
				# Counts how many instance are in col x
	setkey(DT, x)
				# The key is set to the variable x
	fread()		# Read a data table. It's 10 times faster as data frames			
	
	# Example	
	fread("data/COES_Microcephaly-2016-06-25.csv",
      select = c("location", "value", "unit")) %>%
	  dplyr::slice(1:3)
	  
	# Careful 
	DT2 <- DT is a shallow copy. Any change of DT will be reported on DT2. Use copy()

	# If the data is too large, use a RDBMS
	R generic package 	DBI
	R specific package	RMySQL, ROracle, RSQLServer, RSQLite, RPostgres
	
	# Further resources
	* The latest development version [https://r-forge.r-project.org/scm/viewvc.php/pkg/NEWS?view=markup&root=datatable](https://r-forge.r-project.org/scm/viewvc.php/pkg/NEWS?view=markup&root=datatable)
	* Here is a list of differences between data.table and data.frame[http://stackoverflow.com/questions/13618488/what-you-can-do-with-data-frame-that-you-cant-in-data-table](http://stackoverflow.com/questions/13618488/what-you-can-do-with-data-frame-that-you-cant-in-data-table)
	* Notes based on Raphael Gottardo's notes [https://github.com/raphg/Biostat-578/blob/master/Advanced_data_manipulation.Rpres](https://github.com/raphg/Biostat-578/blob/master/Advanced_data_manipulation.Rpres), who got them from Kevin Ushey.

	
	
	
# Other commands

	# Subset with plyr
	library(plyr)
	arrange(X, desc(var1), var2)	# Sort in descending order along var1 and along var2 (if there are duplicates)
	
	# Merge with plyr
	arrange(join(df1,df2),id)
	join_all(df1,df2,df3)
		
	# sapply with plyr
	ddply(InsectSprays, .(spray), summarize, sum=sum(count))	
	
	# Creates a classification matrix 
	xtabs(a ~ b + c, data = D)
	
	# Creates a classification matrix for each var, then put it into a flat one
	xt <- xtabs(a ~ ., data = D)
	fltable(xt)	
	
	# Returns a vector based on test (warning coercion will happen)
	ifelse(test, true, false)
	ifelse(x < 0, TRUE, -x)
	
	# Divide a range into n break
	cut(x, breaks = n)
	
	# Round a value to its n significant value
	signif(x, digits = n)

	# Merge two dataframes using the col "id" and "sol_id"
	merge(x, y, by.x = "id", by.y = "sol_id", all = TRUE)
	# It is not recommended to merge(x, y, all=TRUE) because intersect() will merge all the columns together, creating a huge object
	

