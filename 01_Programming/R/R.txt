# Command Line 

	# Navigate
	getwd()				
	setwd()
	ls()				# List objects in the workspace
	dir()				# List files in wd
	dir.create()		# Create folder
	unlink()			# Delete folder
	file.create() file.exists() file.info() file.copy() file.rename()
	
	rm(list = ls())		# Empty the environment
	cat("\014")  		# Clean the console

	
# Install package

	install.packages(c("NAME1","NAME2"))
	Rstudio -> Tools -> Install packages...
	
	# Installing R package from Bioconductor (bioconductor.org/install/)
	source("http://bioconductor.org/biocLite.R")
	biocLite()
	biocLite(c("GenomicFeatures", "AnnotationDbi"))
	
	# Load packages
	library(NAME)
	search()
	
	# Load a .R
	source("NAME")
	ls()
	
	
# Common operations
	<-					# Assignments	
	?print				# Get help on the print function
	?`:`				# Get help on an operator
	args()				# See list of arguments
	str()				# Short help, display arguments
	table()				# Count the number of factors
	table(x,y)			# Same but two-dimensional
	summary()			# Longer help, works on objects
	object.size()		# Provides an estimate of the memory used by an R object
	quantile()			# Get information on the quantiles
	View()				# Invoke a spreadsheet viewer
	fix()				# Open a data editor
	
	1:20				# Integer operation
	1					# Gives a numeric object
	1L					# Gives an integer object
	Inf	pi				
	
	attributes()		# Access the attributes of an object
	class()				# Get the class of an object
	typeof()			# Get the type of data
	is.na(), is.nan()	# Check if NA (missing), NaN
	na.omit()			# Generic way to deal with missing data
	as.logical(x)		# Explicit coertion, may result in NA
	as.numeric(x), as.character(x), as.complex
	
	plot()				# Simple x, y plot
	boxplot(m ~ c)		# Plot with mean and median with m on x-axis and c on y-axis
	hist()				# Plot histogram
	pairs()				# Plot all possible scatterplots
	pairs(~ m + d + h + w + a, DF)
	identify(x, y, name)# Click on data point to have it's name


# Data types	
	
	c()					# Generic function that combines objects
	c(0.5,0.6)
	c(TRUE, 5)			# Coercion happens, elements are casted in the same class, here numeric	
		
	vector()			# Empty vector
	vector("numeric", length = 10)	# [1] 0 0 0 0 0 0 0 0 0 0
			
	list(1, "a", TRUE, F, 1 + 4i)	# List initialization
	
	m <- matrix(1:6, nrow = 2, ncol = 3)
	dim(m)				# Create a matrix and get its dimension
	m <- 1:10
	dim(m) <- c(2,5)	# Modify an object into a matrix
	cbind(), rbind()	# Create matrix by binding columns or rows
	
	x <- factor(c("y","y","n","y","n","m"), levels = c("y","n","m"))
						# Create a factor and define the order of the levels
	table(x)			# Count how many factors
	unclass(x)			# Replace factors with numbers
	
	data.frame(a = 1:4, b = c(T,F,F,T))
	nrow(), ncol()		# Create a data frame (list of same type columns) and get its dimensions
	
	# You can name R objects: vector, list, matrix
	x <- 1:3			
	names(x) <- c("1st", "2nd", "3rd")
	list(a = 1, b = 2, c = 3)
	m <- matrix(1:4, nrow = 2, ncol = 2)
	dimnames(m) <- list(c("a","b"), c("c","d"))
	
	rep(x, times, each)	# Replicate the values of x n times, or each elements ntimes 
	paste(x)			# Concatenate the elements of x
	paste(x,y,sep="")	# Concatenate two vectors of same length, coercion may happen
	
	identical(x,y)		# Check if x is exactly the same as y
	unique(x)			# Returns the vector x but without any duplicates
	

# Subsetting
	
	x[x > "a"]			# Access index 
	u <- x > "a"		# Boolean comparison, u is a logical vector
	
	x[i]				# Extract a list
    x[[i]]				# Extract elements within the list
	x[c(i,j)]			# Extract two elements
	x[-c(i,j)]			# Extract everything but two elements
	
	x[i,  ]				# Access a rows
	x[ , j]				# Access a vector of a column
	x[ , j, drop=FALSE]	# Return a matrix of a column 
	x[i, j]				# Return a vector of elements i,j
	
	x$a					# Extract the list that has the element a
    x$"a"				# Extract the list that has the element "a"
	attach(x); a;		# Extract the list that has the element "a" 
	
	x$p <- y			# Add a column
	x <- cbind(x,y)		# Combine columns
	
	which(x > 5)		# Returns the indices
	x[order(x$a,x$b)]	# Order values according to column a then b (if duplicates)
	
	x %in% c("1","2")	# Same as (x == "1" | x == "2")
	
	# Partial matching
	x <- list(aardvark = 1:5)
	x$a					# Returns [1] 1 2 3 4 5
	x[["a"]]			# Returns NULL
	x[["a",exact=FALSE]]# Returns [1] 1 2 3 4 5
	
	g <- complete.cases(x, y)
	x[g]				# Remove all NA values
	x[!is.na(x) & x > 0]# Example of removing NA values and selecting positives
	
	# Logic
	which(x > 5)		# Returns the index where the element is > 5
	any(x < 0)			# Returns TRUE if at least one element of x < 0
	all(x < 0)			# Returns TRUE if all element of x < 0

	
# Vectorized operation

	x+y, x*y, x/y		# Elements-wise operations that loop
	x %*% y				# True matrix multiplication
	
	
# Reading / Writing Data
	read.table	write.table		# tabular data
	read.csv 	write.csv		# tabular data separated by commas
	readLines	writeLines		# lines of a text file
	source 		dump 			# R code files
	dget 		dput			# R code files
	load		save			# saved workspaces
	unserialize	serialize		# single R objects in binary form
	
	read.table important arguments:
		file, the name of a file, or a connection
		header, logical indicating if the file has a header line
		sep, a string indicating how the columns are separated
		colClasses, a character vector indicating the class of each column in the dataset
		nrows, the number of rows in the dataset
		comment.char, a character string indicating the comment character
		skip, the number of lines to skip from the beginning
		stringsAsFactors, should character variables be coded as factors?
		Note: lines beginning with # are skipped

	Reading large table is slow, use colClasses to help (e.g. colClasses = "numeric") or a somewhat dirty way
		initial <- read.table("datatable.txt", nrows = 100)
		classes <- sapply(initial, class)
		tabAll <- read.table("datatable.txt", colClasses = classes)
	
	# One object
	dput(y, file = "y.R")
	new.y <- dget("y.R")
	
	# Multiple objects
	dump(c("x", "y"), file = "data.R")
	rm(x, y)
	source("data.R")
	

# Interfaces
	file (name = "", open = "")	# Open a file, use "r", "w", "a", "b" for open
	
	con <- file("foo.txt", "r")
	data <- read.csv(con)
	close(con)
		OR
	data <- read.csv("foo.txt") # Same as above
	
	# Others
	gzfile, bzfile	# Open a compressed file
	url				# Open a connection to a webpage
	
	con <- gzfile("words.gz")
	x <- readLines(con, 10)
	
	con <- url("http://www.jhsph.edu", "r")
	x <- readLines(con)
	
	
# Control Structures
	
	! & | %% 		# NOT AND OR modulus 
	isTRUE(x)		# test if x is true
	
	if () {}
	else if () {}
	else {}
	
	for (X in Y) {}
	seq_along(x)	# Creates a indexed sequence for x 
	seq_len(x)		# Creates a sequence of length x
	(i in start:end)
	(j in seq_along(number))
	(k in letters)
	
	while() {}
	
	repeat {}		# Behave like a while(TRUE), use break to exit
	next			# Skip an iteration
	break			# Exit the loop
	return()		# Output of the function
	
	
# Functions

	f <- function(ARGUMENTS) {}
					# You can pass functions as arguments, and you can define a function inside another function
	(...)			# You can use ellipsis to accept a variable number of arguments
	

	# Explore the scope of a function's environment
	ls(environment(X))
	get("Y", environment(X))
	
	# Binary operator
	"%m1%" <- function(left, right){
		left * right + 1
	}
	`4 %m1% 5`		# Returns 21	
	
	When should I write a function or a package?
	Your closest collaborator is you six months ago, but you don't reply to emails.

	If you do X once, write code but document it very well so that it can be reproduced.
	If you do X twice, write a function to abstract input/output.
	If you do X three+, write a package with documentation.
	
	
# Dates and Time

	x <- Sys.Date()
	x <- as.Date("1970-01-01")
	
	x <- Sys.time()
	p <- as.POSIXct(x) # Stores as time an integer
	p <- as.POSIXlt(x, tz) # Stores time and others information
	
	# If the date is not conform use strptime
	# This allow +, -, ==, >= 
	datestring <- c("January 10, 2012 10:40", "December 9, 2011 9:10")
	x <- strptime(datestring, "%B %d, %Y %H:%M")
  
	
# Loop functions

	# apply - apply FUN on array X to be applied over MARGIN (1 rows, 2 cols, c(1,2) for both)
	apply(X, MARGIN, FUN, ...)
	
	# Note that these are way faster
	rowSums = apply(x, 1, sum)
	rowMeans = apply(x, 1, mean)
	colSums = apply(x, 2, sum)
	colMeans = apply(x, 2, mean)
	
	# lapply - apply FUN on list X (if X is not a list, it will be coerced), return a list
	lapply(X, FUN, ...)
	lapply(x, function(elt) elt[,1])	# Use an anonymous function
	
	# sapply is like lapply, but will simplify the return argument into a vector, matrix
	# vapply is similar to sapply, but a bit optimized
	# rapply is when you want to use lapply recursively into nested lists
	
	# mapply - multivariate apply, use when you want vectorized arguments
	mapply(FUN, ..., MoreArgs = NULL, SIMPLIFY = TRUE, USE.NAMES = TRUE)
					# ... are the arguments to apply FUN over
					# MoreArgs are the arguments for FUN
					# SIMPLIFY indicates whether to simplify the output
	mapply(FUN, 1:5, 1:5, 2)
	
	# tapply - apply FUN over INDEX subsets of a vector
	tapply(X, INDEX, FUN = NULL, ..., simplify = TRUE)
	INDEX <- c(1,1,2,2)	# For instance, this will group X into 2 groups
	
	# split - takes object x and splits it into groups according to f factors
	split(x, f, drop = FALSE, ...)
	
	# Example: split airquality for each month and apply anonymous function colMeans
	s <- split(airquality, airquality$Month)
	lapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
	OR
	sapply(s, function(x) colMeans(x[, c("Ozone", "Solar.R", "Wind")]))
	
	# Splitting on more than one level, here 2*5 = 10 levels
	f1 <- gl(2, 5); f2 <- gl(5, 2); interaction(f1, f2)
	split(x, list(f1, f2), drop = TRUE)
	

# Debugging

	message			# Generic notification, execution continues
	warning			# Something is wrong, execution continues
	error			# Problem occured, execution stops
	condition		# Something unexpected occured, programmers can create their own conditions
	
	stop()			
	stopifnot()	
	
	invisible(x)	# Return x without printing
	
	traceback()		# Print the call stackof the last uncaught error
	debug(FUN)		# Debug a function by going line by line
	debugonce(FUN) undebug(FUN) isdebugged(FUN)
	browser()		# Interrupts the execution to browse the environment
					http://stat.ethz.ch/R-manual/R-devel/library/base/html/browser.html
	trace()			# Insert debugging code that can be globally de/activated
	recover()		# Navigates the function call stack after a function has thrown an error
	options(error=recover)	# Allows the user to browse the environnment 

	
# R profiler	

	system.time()	# Returns the amount of time used to evaluate the expression
					# user time = CPU time, elapsed time = real time 
									
	Rprof()			# Starts the profiler, use when the code is not too fast
	summaryRprof()	# Summarizes the results of Rprof()
	$by.total		# Time spent in the function alone and its sublevels
	$by.self		# Time spent in the function alone
	
	# Compare two functions and plot the result
	library(microbenchmark, ggplot2)
	profile <- microbenchmark(a <- rnorm(1000), b <- mean(rnorm(1000)))
	autoplot(profile)
	
	# Identify bottlenecks
	profvis
	https://rstudio.github.io/profvis/index.html
	
	# More reading on performance
	http://adv-r.had.co.nz/Performance.html
	
	
# Memory usage
	library(pryr)
	mem_used()
	object_size(var)
	
	# Print the 5 largest objects
	library(magrittr)
	sapply(ls(), function(x) object_size(get(x))) %>% sort %>% tail(5)
	
	# remove a variable and see how much it left
	mem_change(rm(var))
	
	# R has an automatic garbage collection, you can print some stuff with
	gc()
	
	
# Statistics

	rnorm(n, mean = 0, sd = 0)			
					# Generates n random normal variates
	dnorm(n, mean = 0, sd = 0)
					# Evaluate the normal probability density (area P(x = n))
	pnorm(q, mean = 0, sd = 0)
					# Evaluate the cumulative distribution function (area under P(x <= q))
	qnorm(p, mean = 0, sd = 0)
					# Evaluate the quantile percentile
	rpois, dpois, ppois, qpois	# Every distribution has r,d,p,q functions
	
	set.seed()		# Ensures reproductability of random results
	sample()		# Draws randomly from a set of scalars
	
	integrate(p,x,y)# Compute the area of pdf p from x to y
	# Create 4 quantiles on distribution
	cutpoints <- quantile(distr ,seq(0,1,length = 4))
	cut(distr, cutpoints)
	
	
# Functional programming
	map_lgl(), map_chr(), map_dbl()
		take an input (logical, characters or double) and apply a function on it.
	
	map_if() apply the second function if the first is TRUE
		map_if(1:5, function(x){ x %% 2 == 0}, function(y){y^2}) %>% unlist()
		[1] 1 4 3 16 5
	
	map_at() apply function at certain indices (here 1, 3, 5)
		map_at(seq(100, 500, 100), c(1, 3, 5), function(x){x - 10}) %>% unlist()
		[1]  90 200 290 400 490
	
	map2_chr() apply the function to each char
		map2_chr(letters, 1:26, paste)

	The pmap() family works like map() but over a list of list.
	
	reduce()/reduce_right() starts with the first/last input then aggreagates the second with the first/last with the second to last.
	
	contains(var, pattern)
		returns TRUE if var contain pattern
	detect(start:end, function)
		returns the first result using function as a filter
	detect_index(start:end, function)
		returns the first index where fun returned TRUE
	
	keep(), discard(), every(), some() 
		returns all TRUE, all FALSE, TRUE if every/some element are TRUE
	
	compose() combines functions together
		n_unique <- compose(length, unique)
		# n_unique <- function(x){ length(unique(x))}
	
	partial() binds values to a function
		mult_three_n <- function(x, y, z){x * y * z}
		mult_by_15 <- partial(mult_three_n, x = 3, y = 5)
		mult_by_15(z = 4)
		[1] 60
	
	
# Expressions, environment
	v <- "2 + 2"
	exp <- parse(text = v)
	eval(exp)
	deparse(exp)
	
	my_new_env <- new.env()
	assign("y", 9, envir = my_new_env)
	get("y", envir = my_new_env)
	ls(), rm(), exists(), search()
	
	<<- To assign value in the parent environment
	
	
# Object Oriented Programming
	S3
	shape_s3 <- function(side_lengths){structure(list(side_lengths = side_lengths), class = "shape_S3")}
	is_square.shape_S3 <- function(x){
		length(x$side_lengths) == 4 && x$side_lengths[1] == x$side_lengths[2] &&
		x$side_lengths[2] == x$side_lengths[3] &&x$side_lengths[3] == x$side_lengths[4]}

	square_4 <- shape_s3(c(4, 4, 4, 4))
	class(square_4)
	[1] "shape_S3"
	is_square(square_4)

	S4
	# More to learn
	

# Editing text variables

	if(!file.exists("./data")){dir.create("./data")}
	fileUrl <- "https://data.baltimorecity.gov/api/views/dz54-2aru/rows.csv?accessType=DOWNLOAD"
	download.file(fileUrl,destfile="./data/cameras.csv",method="curl")
	cameraData <- read.csv("./data/cameras.csv")
	
	# Change to lowercase ("crossStreet" -> "crossstreet")
	tolower(names(cameraData))
	
	# Split names like "location.1" -> "location", "1" 
	splitNames = strsplit(names(cameraData),"\\.")
	
	# Remove underscores "review_id" -> "reviewid"
	sub("_","",names(reviews),)		# Replace one
	gsub("_","",testName)			# Replace all
	
	# Find matching patterns
	grep("Alameda",cameraData$intersection)	
									# Returns the indices
	grepl("Alameda",cameraData$intersection)
									# Returns a logical array
	grep("Alameda",cameraData$intersection,value=TRUE)
									# Returns the strings
	
	# More useful string functions
	library(stringr); 
	nchar()							# Counts how many letters
	substr("Jeffrey Leek",1,7)		# Keeps only the string from 1 to 7
	paste("Jeffrey","Leek",sep)		# Paste two strings together (sep =" ")
	paste0("Jeffrey","Leek")		# Paste two strings together (sep ="")
	str_trim("Jeff      ")			# remove spaces
	
	
# Text Processing and regex
	# You can pass a vector to paste()
	two_cities <- c("best", "worst")
	paste("It was the", two_cities, "of times.")
	
	
	# regex function
	grepl(regex, string)	Return bool
	grep(r, s)				Return first match
	sub(r, r2, s)			Replace into s the first r with r2
	gsub(r, r2, s)			Same as sub but for all the r patterns
	strsplit()
	
	# metacharacters
	.				Any single character
	*				Zero or more
	+				One or more 
	i{3}			Matches exactly 3 "i"
	i{2,3}			Contains between 2 and 3 adjacent "i"
	(iss){2,}		Contains 2 or more adjacent "iss"
	\\w, \\d, \\s	Contains words, digits, whitespaces
	\\W, \\D, \\S	Do not contain words, digits, whitespaces
	\n, \t			Newline, tabs
	[aeiou]			Match with any lowercase vowels
	[^aeiou]		Match with anything but lowercase vowels
	[a-mA-M]		Match with any letter
	[Bb][Aa]		Either Ba, BA, ba or bA is detected
	^a, a$			Begins with, ends with
	sp|st			Match sp or st
	
	
	[0-9][a-zA-Z]	Specifying a range
	[^?.]$			Match everything that does not end with . or ?
	9.11			. refers to any character
	^good|bad	vs 	^(good|bad)		
	([Ww]\.)? Bush	The W. or w. pattern is optional
	(.*)			Match anything that is in parenthesis (24, M), (eat + west) and ()
	[0-9]+ (.*)[0-9]+
					Math anything between (and including) two numbers	
	( +[^ ]+ +){1,5}Match "Space then word then space" one to five times
	([a-z]+) +\1 	Match a word two times in a row ("so so")
	^s(.*)s			Greedy match for "s.*s"
	^s(.*?)s$
	
	
	example: start with a capitaized vowel, ends with a vowel
	start_end_vowel <- "^[AEIOU]{1}.+[aeiou]{1}$"
	
	
	
	
	
	
	
