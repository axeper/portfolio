# Four things you should have
	
	1. Raw Data
	2. Tidy dataset (i.e. human-readable)
	3. A codebook describing each variable, its units and its values in the tidy dataset.
		It is recommended to describe the summary choices, the experimental study design.		
	4. An instruction list to go from 1 -> 2 & 3
	

# Download data

	Make sure you're in the right folder getwd(), setwd()
	
	if(!file.exists("data")) { dir.create("data") }
	fileURl <- ""
	download.file(fileURl, destfile = "cam.csv") 	# maybe add method = "curl"
	dateDownloaded <- date()


# CSV

	read.table(), read.csv(), read.csv2()
		sep (how is data separated)
		header (is there a header line)
		quote = "" (set no quoted values)
		na.strings (how is a missing value represented) 
		nrows (how many rows to read)
		skip (number of lines to skip)

		
# Excel

	library(xlsx)
	read.xlsx(), read.xlsx2()
		sheetIndex (which sheet to read)
		colIndex = 1:4 (use to extract subsets)
		rowIndex = 2:3 (use to extract subsets)
	write.xlsx()
	
	# Further resources
	- The [XLConnect](http://cran.r-project.org/web/packages/XLConnect/index.html) package has more options for writing and manipulating Excel files
	- The [XLConnect vignette](http://cran.r-project.org/web/packages/XLConnect/vignettes/XLConnect.pdf) is a good place to start for that package	
	

# XML

	library(XML)
	doc <- xmlTreeParse(url, useInternal = TRUE)
	rootNode <- xmlRoot(doc)
	xmlName(rootNode)
	names(rootNode)
	rootNode [[1]] [[1]]
	
	Using sapply for xml:
		xmlSApply(rootNode, xmlValue)
	
	Using XPath:
		/node (top level node)
		//node (node at any level)
		node[@attr-name="x"] (node with an attribute name, called "x")
		
		xpathSApply(rootNode, "//name", xmlValue)
	
	# Further resources	
	- Official XML tutorials [short](http://www.omegahat.org/RSXML/shortIntro.pdf), [long](http://www.omegahat.org/RSXML/Tour.pdf)
	- [An outstanding guide to the XML package](http://www.stat.berkeley.edu/~statcur/Workshop2/Presentations/XML.pdf)
	

# JSON

	library(jsonlite)
	jsonData <- fromJSON(url)
	names(jsonData)
	jsonData$col1$col2
	
	Data frame to/from JSON:
		my_json <- toJSON(df, pretty = TRUE)
		iris2 <- fromJSON(my_json)

	# Further resources
	- A good tutorial on jsonlite - [http://www.r-bloggers.com/new-package-jsonlite-a-smarter-json-encoderdecoder/](http://www.r-bloggers.com/new-package-jsonlite-a-smarter-json-encoderdecoder/)
	- [jsonlite vignette](http://cran.r-project.org/web/packages/jsonlite/vignettes/json-mapping.pdf)

	
	
# HDF5

	source("http://bioconductor.org/biocLite.R")
	biocLite("rhdf5")
	library(rhdf5)
	created = h5createFile("example.h5")

	# Read data (here read only the subset "foo/A" and you could add an index)
	readA = h5read("example.h5","foo/A", index = )
	
	# Create a group and write
	created = h5createGroup("example.h5","foo")
	h5write(B, "example.h5","foo/foobaa/B")		# Write B to a group
	h5write(df, "example.h5","df")				# Write directly a dataset
	h5write(c(12,13,14),"example.h5","foo/A",index=list(1:3,1))
												# Write the chunk c(,,) to the index
	h5ls("example.h5")
	
	# Further resources
	- The rhdf5 tutorial:[http://www.bioconductor.org/packages/release/bioc/vignettes/rhdf5/inst/doc/rhdf5.pdf](http://www.bioconductor.org/packages/release/bioc/vignettes/rhdf5/inst/doc/rhdf5.pdf)	
	- The HDF group has informaton on HDF5 in general [http://www.hdfgroup.org/HDF5/](http://www.hdfgroup.org/HDF5/)
	
	
# MySQL

	# Retrieve a database
	library(RMySQL)
	ucscDb <- dbConnect(MySQL(),user="genome", host="genome-mysql.cse.ucsc.edu")
	result <- dbGetQuery(ucscDb,"show databases;")
	dbDisconnect(ucscDb)			# VERY IMPORTANT
	
	# Sending a mysql command
	dbListFields(hg19,"affyU133Plus2")
	dbGetQuery(hg19, "select count(*) from affyU133Plus2")
	
	# Read a table
	affyData <- dbReadTable(hg19, "affyU133Plus2")
	
	# Read subset
	query <- dbSendQuery(hg19, "select * from affyU133Plus2 where misMatches between 1 and 3")
	affyMis <- fetch(query); quantile(affyMis$misMatches)

	# Fetch only a small dataset
	affyMisSmall <- fetch(query,n=10); dbClearResult(query);

	# RMySQL
	https://cran.r-project.org/web/packages/RMySQL/RMySQL.pdf
	# MySQL commands
	http://www.pantz.org/software/mysql/mysqlcommands.html

	# Further resources
	- RMySQL vignette [http://cran.r-project.org/web/packages/RMySQL/RMySQL.pdf](http://cran.r-project.org/web/packages/RMySQL/RMySQL.pdf)
	- List of commands [http://www.pantz.org/software/mysql/mysqlcommands.html](http://www.pantz.org/software/mysql/mysqlcommands.html)
	- A nice blog post summarizing some other commands [http://www.r-bloggers.com/mysql-and-r/](http://www.r-bloggers.com/mysql-and-r/)
	
	
# Webscraping

	# Get the HTML page
	htmlCode = readLines(url)
	close(con)
	
	# Parse its content
	library(XML)
	html <- htmlTreeParse(url, useInternalNodes=T)
	xpathSApply(html, "//title", xmlValue)
	xpathSApply(html, "//td[@id='col-citedby']", xmlValue)
	
	# Using httr
	library(httr); html2 = GET(url)
	content2 = content(html2,as="text")
	parsedHtml = htmlParse(content2,asText=TRUE)
	xpathSApply(parsedHtml, "//title", xmlValue)

	# Accessing websites with passwords
	pg2 = GET("http://httpbin.org/basic-auth/user/passwd", authenticate("user","passwd"))

	# Using handles (keeps you authetificated using cookies)
	google = handle("http://google.com")
	pg2 = GET(handle=google,path="search")
	
	# Example
	library(httr)
	meso_url <- "https://mesonet.agron.iastate.edu/cgi-bin/request/asos.py/"
	GET(url = meso_url, query = list(station = "DEN", data = "sped", 
		year1 = "2016", month1 = "6", day1 = "1", year2 = "2016", 
		month2 = "6", day2 = "30", tz = "America/Denver", format = "comma")) %>%
	content() %>% 
	read_csv(skip = 5, na = "M") %>% 
	slice(1:3)
	
	
	# Further resources
	- R Bloggers has a number of examples of web scraping [http://www.r-bloggers.com/?s=Web+Scraping](http://www.r-bloggers.com/?s=Web+Scraping)
	- The httr help file has useful examples [	http://cran.r-project.org/web/packages/httr/httr.pdf](http://cran.r-project.org/web/packages/httr/httr.pdf)
	- [rvest for webscraping](https://github.com/hadley/rvest)
	- [JSON, XML: jsonlite, xml2](https://cran.r-project.org/web/views/WebTechnologies.html)
	

# APIs
	
	# Some API's with R interfaces
	- [twitter](https://dev.twitter.com/) and [twitteR](http://cran.r-project.org/web/packages/twitteR/index.html) package
	- [figshare](http://api.figshare.com/docs/intro.html) and [rfigshare](http://cran.r-project.org/web/packages/rfigshare/index.html)
	- [PLoS](http://api.plos.org/) and [rplos](http://cran.r-project.org/web/packages/rplos/rplos.pdf)
	- [rOpenSci](http://ropensci.org/packages/index.html)
	- [Facebook](https://developers.facebook.com/) and [RFacebook](http://cran.r-project.org/web/packages/Rfacebook/)
	- [Google maps](https://developers.google.com/maps/) and [RGoogleMaps](http://cran.r-project.org/web/packages/RgoogleMaps/index.html)
	
	Quandl: Quandl (financial data), 
	RGoogleAnalytics: Google Analytics
	censusr, acs: United States Census
	WDI, wbstats: World Bank
	GuardianR, rdian: The Guardian Media Group
	blsAPI: Bureau of Labor Statistics
	rtimes: New York Times
	dataRetrieval, waterData: United States Geological Survey			   
	rnoaa: National Oceanic and Atmospheric Administration	

	
	# Accessing Twitter
	myapp = oauth_app("twitter", key="yourConsumerKey",secret="yourConsumerSecret")
	sig = sign_oauth1.0(myapp, token = "yourToken", token_secret = "yourTokenSecret")
	homeTL = GET("https://api.twitter.com/1.1/statuses/home_timeline.json", sig)
	
	# Convert the data to a dataframe
	json1 = content(homeTL)
	json2 = jsonlite::fromJSON(toJSON(json1))
	
	# Further resources
	- [https://dev.twitter.com/docs/api/1.1/overview](https://dev.twitter.com/docs/api/1.1/overview
	

# RDBMS
	# Small example
	install.packages("RODBC")
	library(RODBC)
	conn <- odbcConnect("training2", uid="user", pwd="password")
	housing_data <- sqlQuery(conn, "select serialno, state, persons, rooms from housing where hinc > 1000000")
	
	# Further resources
	- RPostresSQL provides a DBI-compliant database connection from R. Tutorial-[https://code.google.com/p/rpostgresql/](https://code.google.com/p/rpostgresql/), help file-[http://cran.r-project.org/web/packages/RPostgreSQL/RPostgreSQL.pdf](http://cran.r-project.org/web/packages/RPostgreSQL/RPostgreSQL.pdf)
	- RODBC provides interfaces to multiple databases including PostgreQL, MySQL, Microsoft Access and SQLite. Tutorial - [http://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf](http://cran.r-project.org/web/packages/RODBC/vignettes/RODBC.pdf), help file - [http://cran.r-project.org/web/packages/RODBC/RODBC.pdf](http://cran.r-project.org/web/packages/RODBC/RODBC.pdf)
	- RMongo [http://cran.r-project.org/web/packages/RMongo/RMongo.pdf](http://cran.r-project.org/web/packages/RMongo/RMongo.pdf) (example of Rmongo [http://www.r-bloggers.com/r-and-mongodb/](http://www.r-bloggers.com/r-and-mongodb/)) and [rmongodb](http://cran.r-project.org/web/packages/rmongodb/rmongodb.pdf) provide interfaces to MongoDB.
	
	
	
# Other packages

	# Foreign package (arff, dta, mtp, octave, spss, xport)
	[http://cran.r-project.org/web/packages/foreign/foreign.pdf](http://cran.r-project.org/web/packages/foreign/foreign.pdf)
	
	# Reading images
	- jpeg - [http://cran.r-project.org/web/packages/jpeg/index.html](http://cran.r-project.org/web/packages/jpeg/index.html)
	- readbitmap - [http://cran.r-project.org/web/packages/readbitmap/index.html](http://cran.r-project.org/web/packages/readbitmap/index.html)
	- png - [http://cran.r-project.org/web/packages/png/index.html](http://cran.r-project.org/web/packages/png/index.html)
	- EBImage (Bioconductor) - [http://www.bioconductor.org/packages/2.13/bioc/html/EBImage.html](http://www.bioconductor.org/packages/2.13/bioc/html/EBImage.html)

	# Reading GIS data
	- rgdal - [http://cran.r-project.org/web/packages/rgdal/index.html](http://cran.r-project.org/web/packages/rgdal/index.html)
	- rgeos - [http://cran.r-project.org/web/packages/rgeos/index.html](http://cran.r-project.org/web/packages/rgeos/index.html)
	- raster - [http://cran.r-project.org/web/packages/raster/index.html](http://cran.r-project.org/web/packages/raster/index.html)

	# Reading music data
	- tuneR - [http://cran.r-project.org/web/packages/tuneR/](http://cran.r-project.org/web/packages/tuneR/)
	- seewave - [http://rug.mnhn.fr/seewave/](http://rug.mnhn.fr/seewave/)
		
